{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Contextually","text":"<p>The Universal Computational Fabric. Contextually is a declarative, multi-stage automation platform for modern data and operations teams. It's built around a powerful command-line shell, <code>cx</code>, that functions as a stateful Workspace IDE and an AI Reasoning Partner.</p> <p>Our core philosophy is to eliminate context fragmentation\u2014the loss of lineage, intent, and nuance when work flows between different tools, people, and AI agents.</p> <ul> <li> Getting Started Tutorial</li> </ul> <p>Our 5-minute guide to installing <code>cx</code> and running your first command. This is the best place for new users to begin their journey.</p> <p> Start the Tutorial</p> <ul> <li> The Agentic Shell</li> </ul> <p>Discover the AI Assistant built into <code>cx</code>. Learn to translate natural language into commands with <code>//</code> and solve complex problems with <code>agent</code>.</p> <p> Meet Your Assistant</p> <ul> <li> Application Ecosystem</li> </ul> <p>Explore Applications\u2014complete, \"toolkit-in-a-box\" solutions that bundle flows, queries, and blueprints to solve real-world problems.</p> <p> Find Packaged Solutions</p> <ul> <li> Blueprint Foundation</li> </ul> <p>Understand Blueprints, the version-controlled packages that contain the \"knowledge\" of how to interact with any external API or service.</p> <p> Learn about Blueprints</p>"},{"location":"#our-philosophy-the-contextually-way","title":"Our Philosophy: The Contextually Way","text":"<p>Contextually is built on three foundational principles that guide every architectural decision.</p> <ul> <li>Specification-First</li> </ul> <p>We don't build integrations for services; we build engines for protocols. We onboard new services by ingesting their machine-readable specifications (like OpenAPI) with the <code>cx compile</code> command, not by writing bespoke code.</p> <ul> <li>Declarative over Imperative</li> </ul> <p>All workflows are defined as simple, version-controllable YAML scripts. The what is in the script; the how is in the engine. This makes workflows readable, portable, and maintainable.</p> <ul> <li>Compose, Don't Command</li> </ul> <p>Our platform is built on the UNIX philosophy. Small, powerful tools (Blueprints, Flows, agentic commands) are composed together using pipes (<code>|</code>) to create complex, emergent workflows.</p>"},{"location":"concepts/agentic-shell/","title":"Explanation: The Agentic Shell","text":"<p>The <code>cx</code> interactive shell is designed as a powerful \"Workspace IDE\"\u2014a stateful environment for composing commands, managing assets, and building workflows. The shell's most advanced capability is its integrated agentic layer, which transforms the IDE into an intelligent reasoning partner.</p> <p>This document explains the philosophy and architecture behind the <code>cx</code> agent.</p>"},{"location":"concepts/agentic-shell/#from-composition-to-collaboration-the-intent-engine","title":"From Composition to Collaboration: The Intent Engine","text":"<p>While <code>cx</code> provides powerful primitives for manual work (<code>|</code>, <code>=</code>), its true potential is unlocked by bridging the gap between high-level user intent and low-level command execution. This is the core function of the shell's Intent Engine. The engine provides a spectrum of assistance, allowing you to choose the right level of collaboration for any task.</p> <ul> <li> <p>Fast Path (<code>//</code>): For immediate, in-context assistance, the Translate feature acts as a \"fast thinking\" co-pilot, providing single-shot, natural-language-to-command translation. Its purpose is to lower the cognitive barrier to using the shell and accelerate common tasks.</p> </li> <li> <p>Deliberate Path (<code>agent</code>): For complex, multi-step problems, you engage the full Reasoner. This is the \"slow thinking\" component\u2014a deliberative, stateful partner that can plan and execute complex workflows.</p> </li> </ul>"},{"location":"concepts/agentic-shell/#the-care-architecture-a-team-of-specialists","title":"The CARE Architecture: A Team of Specialists","text":"<p>The <code>agent</code> command is powered by the Composite Agent Reasoning Engine (CARE), a hierarchical architecture inspired by how human expert teams operate. Instead of a single, monolithic AI, CARE is a team of specialist agents, each with a distinct role.</p>"},{"location":"concepts/agentic-shell/#1-the-planner-agent","title":"1. The Planner Agent","text":"<ul> <li>Role: The High-Level Strategist.</li> <li>Function: When you provide a goal (e.g., <code>agent \"Onboard the Spotify API...\"</code>), the Planner is the first agent to act. It looks at your goal and the high-level context of your workspace (available flows, recent commands) and creates a concise, logical, high-level plan. It thinks in terms of meta-actions, like \"Compile the blueprint,\" not specific command syntax.</li> </ul>"},{"location":"concepts/agentic-shell/#2-the-tool-specialist-agent","title":"2. The Tool Specialist Agent","text":"<ul> <li>Role: The Expert Technician.</li> <li>Function: The Tool Specialist receives the Planner's strategy and focuses on executing a single step. It is given a \"Mission Briefing\"\u2014the original goal, the full plan, and any facts discovered so far\u2014to ensure it has all the context it needs. It then uses its knowledge of the shell's grammar and available tools to generate a precise, syntactically perfect <code>cx</code> command to accomplish that single step.</li> </ul>"},{"location":"concepts/agentic-shell/#3-the-analyst-agent","title":"3. The Analyst Agent","text":"<ul> <li>Role: The Observer and Sense-Maker.</li> <li>Function: After a command is executed, the Analyst agent examines the result (the \"observation\"). Its job is to interpret what happened. Did the command succeed? Did it reveal a new, important piece of information (like a URL or an ID)? Or did it fail in a way that invalidates the entire plan? The Analyst updates the team's shared understanding (the \"belief state\") and provides a concise summary, allowing the loop to continue to the next step or escalate back to the Planner for re-planning.</li> </ul> <p>This structured, collaborative process allows the <code>cx</code> agent to break down complex problems and solve them more reliably and transparently than a single monolithic model.</p>"},{"location":"concepts/application-ecosystem/","title":"Explanation: The Application Ecosystem","text":"<p>While the <code>cx</code> shell provides powerful, low-level primitives like Blueprints and Flows, the Application Ecosystem provides a higher level of abstraction: complete, packaged solutions. Understanding this ecosystem is key to leveraging the full collaborative power of the Contextually platform.</p>"},{"location":"concepts/application-ecosystem/#the-problem-from-tools-to-solutions","title":"The Problem: From Tools to Solutions","text":"<p>A blueprint is like a single function in a library. A flow is like a single script. They are powerful tools, but a user still needs to compose them to solve a business problem. This requires significant domain knowledge and setup time.</p> <p>The Monthly Wyndham Report is a perfect example. To make it work, a user needs: - The MSSQL blueprint - The SendGrid blueprint - The <code>get-monthly-wyndham-transactions.sql</code> query - The <code>build-wyndham-report-artifacts.transformer.yaml</code> script - The <code>wyndham_report_email.html</code> template - The final <code>run-monthly-wyndham-report.flow.yaml</code> orchestrator - The knowledge of how to configure the two required connections.</p> <p>Asking a new team member to assemble all of this manually is slow and error-prone.</p>"},{"location":"concepts/application-ecosystem/#the-solution-applications-as-installable-toolkits","title":"The Solution: Applications as Installable Toolkits","text":"<p>A Contextually Application is a self-contained, versioned \"toolkit-in-a-box\" that bundles all these assets together. The <code>cx app install</code> command acts as a magic wand, orchestrating the entire setup process in a single step.</p> <p>This is achieved through a declarative, dependency-first model:</p> <ul> <li>No Redundancy: Applications do not bundle their required blueprints. They simply declare them as dependencies in an <code>app.cx.yaml</code> manifest. The <code>cx</code> shell uses its built-in resolver to download and cache these blueprints on-demand, ensuring efficiency and reusability.</li> <li>Guided Setup: The manifest also declares the <code>required_connections</code>. The installer reads this and launches an interactive wizard, guiding the user through creating and configuring every necessary connection.</li> <li>Discoverability: A public registry, hosted in the <code>flowcontextually/applications</code> repository, provides a searchable \"App Store\" for official and community-vetted solutions, accessible via <code>cx app search</code>.</li> <li>Private Distribution: The system is designed for enterprise use, allowing teams to install internal applications directly from private Git repository URLs.</li> </ul> <p>By elevating the unit of sharing from a single script to a complete, documented, and easily installable solution, the Application Ecosystem transforms the <code>cx</code> shell from a personal productivity tool into a powerful platform for team and community collaboration.</p>"},{"location":"concepts/blueprint-ecosystem/","title":"Explanation: The Blueprint Ecosystem","text":"<p>At the heart of Contextually is the Blueprint Ecosystem, a version-controlled, multi-layered package management system for integrations. Understanding this system is key to mastering the full power of the <code>cx</code> shell and the Contextually platform.</p>"},{"location":"concepts/blueprint-ecosystem/#the-core-problem","title":"The Core Problem","text":"<p>A scalable integration platform must manage the \"knowledge\" of how to interact with thousands of external services. This includes API endpoints, authentication methods, request parameters, and response shapes. Hardcoding this logic into a monolithic application is fragile and unsustainable. It creates a bottleneck where every new integration requires a change to the core application.</p>"},{"location":"concepts/blueprint-ecosystem/#the-solution-blueprints-as-self-contained-packages","title":"The Solution: Blueprints as Self-Contained Packages","text":"<p>Contextually solves this by treating each integration as a self-contained, versioned \"package\" or \"Blueprint\". A blueprint is a directory containing a collection of files that fully describe how to interact with a specific version of an external service.</p> <p>A complete blueprint package contains:</p> <ul> <li><code>blueprint.cx.yaml</code>: The executable contract. This file defines the base URL, authentication methods, and a list of named <code>action_templates</code> for the API.</li> <li><code>schemas.py</code>: A file containing Pydantic models for the API's data structures and action parameters, providing runtime validation and a better developer experience.</li> <li><code>source_spec.json</code>: The original OpenAPI or Swagger specification from which the blueprint was compiled, ensuring auditability and reproducibility.</li> <li><code>README.md</code>: Human-readable documentation for the blueprint.</li> <li><code>examples/</code>: A directory of sample scripts showing how to use the blueprint.</li> </ul> <p>The key benefits of this approach are directly tied to our core architectural principles:</p> <ul> <li>No Breaking Changes: A workflow that depends on <code>community/stripe@v1.2.0</code> will never break when a new version is released, because it points to an immutable, versioned directory.</li> <li>Discoverability: The system is programmatically queryable, allowing the <code>cx</code> shell's tab-completion and future AI agents to discover available capabilities by reading the blueprints.</li> <li>Extensibility: Users and organizations can extend and override official blueprints to suit their specific needs without modifying the original.</li> <li>Frictionless Contribution: The process for community members to contribute new blueprints is simple and highly automated via the <code>cx compile</code> command.</li> </ul>"},{"location":"concepts/blueprint-ecosystem/#the-four-layer-namespace","title":"The Four-Layer Namespace","text":"<p>The filesystem for blueprints is designed as a cascading namespace that allows for clear ownership and prioritized overrides. When <code>cx</code> needs to find a blueprint referenced by a connection (e.g., <code>community/petstore@v2.0</code>), it searches for the package inside the <code>~/.cx/blueprints/</code> directory.</p> <p>The namespaces define a clear hierarchy:</p>"},{"location":"concepts/blueprint-ecosystem/#1-user","title":"1. <code>user/</code>","text":"<ul> <li>Path: <code>~/.cx/blueprints/user/</code></li> <li>Purpose: Your personal workspace. This layer has the highest priority. Any blueprint you create or modify here will override all others. It is the default location for the <code>cx compile</code> command and is perfect for development, testing, and personal scripts.</li> <li>Control: Fully controlled by you.</li> </ul>"},{"location":"concepts/blueprint-ecosystem/#2-organization","title":"2. <code>organization/</code>","text":"<ul> <li>Path: <code>~/.cx/blueprints/organization/</code> (by default)</li> <li>Purpose: A private, shared namespace for your company. This is typically synced from a private Git repository containing proprietary integrations and enterprise-specific customizations of public blueprints.</li> <li>Control: Managed by your organization's administrators.</li> </ul>"},{"location":"concepts/blueprint-ecosystem/#3-community","title":"3. <code>community/</code>","text":"<ul> <li>Path: <code>~/.cx/blueprints/community/</code></li> <li>Purpose: The open-source \"standard library\" of integrations. These blueprints are contributed, reviewed, and maintained by the community. The <code>cx init</code> command populates this directory with its first example.</li> <li>Control: Managed by the Contextually open-source project.</li> </ul>"},{"location":"concepts/blueprint-ecosystem/#4-system","title":"4. <code>system/</code>","text":"<ul> <li>Path: <code>~/.cx/blueprints/system/</code></li> <li>Purpose: A small number of core, essential blueprints maintained directly by the Contextually core team. These are considered part of the application itself.</li> <li>Control: Managed by the Contextually core team.</li> </ul> <p>This layered approach provides a powerful and flexible system for managing integrations at every level, from individual developer experiments to enterprise-wide standards.</p>"},{"location":"concepts/shell-as-ide/","title":"Concepts: The Shell as a Workspace IDE","text":"<p>The <code>cx</code> interactive shell is designed around a core philosophy: your terminal can be more than just a command line; it can be a complete, persistent Integrated Development Environment (IDE) for your data and operations workflows.</p> <p>This is achieved by treating your workspace and its contents as a set of first-class assets that you can create, manage, and compose.</p>"},{"location":"concepts/shell-as-ide/#the-core-assets-of-your-workspace","title":"The Core Assets of Your Workspace","text":"<p>When you work in <code>cx</code>, you are interacting with a few key types of assets. Understanding their roles is key to mastering the shell.</p>"},{"location":"concepts/shell-as-ide/#1-the-session-your-live-workspace","title":"1. The Session: Your Live Workspace","text":"<p>The \"session\" is the ephemeral, in-memory state of your current <code>cx&gt;</code> prompt. It contains two main components:</p> <ul> <li>Active Connections: These are the live, authenticated links to your data sources (APIs, databases) that you create with <code>connect user:my-db --as db</code>. They are temporary shortcuts for your current work.</li> <li>Session Variables: These are the in-memory containers for your data that you create with the assignment operator (<code>my_data = ...</code>). They allow you to hold onto the results of a command and reuse them without having to run the command again.</li> </ul> <p>The <code>session</code> command (<code>session save</code>, <code>session load</code>) allows you to make this ephemeral workspace persistent, so you can close your terminal and restore your exact context later.</p>"},{"location":"concepts/shell-as-ide/#2-the-library-your-reusable-assets","title":"2. The Library: Your Reusable Assets","text":"<p>While the session is your live workbench, the <code>~/.cx/</code> directory acts as your personal library of reusable tools. The shell provides dedicated commands to manage these file-based assets, so you rarely need to interact with the filesystem directly.</p> <ul> <li>Flows (<code>.flow.yaml</code>): These are the most powerful assets. A flow is a persistent, versionable, multi-step workflow. By using the <code>flow run</code> command, you can execute a complex series of actions with a single line. Because they can be parameterized, they act like reusable functions in your personal library.</li> <li>Queries (<code>.sql</code>): For data professionals, storing complex SQL queries as named assets is a huge productivity boost. The <code>query run</code> command allows you to execute these saved queries against any active connection, turning your SQL library into a set of on-demand data retrieval tools.</li> <li>Scripts (<code>.py</code>): For tasks that require the full power of Python, you can save <code>.py</code> scripts to your workspace. The <code>script run</code> command executes them in a sandboxed environment, allowing you to integrate custom logic and analysis directly into your shell pipelines.</li> </ul>"},{"location":"concepts/shell-as-ide/#the-open-command-your-bridge","title":"The <code>open</code> Command: Your Bridge","text":"<p>The <code>open</code> command acts as the seamless bridge between your <code>cx</code> IDE and your other desktop tools. Instead of manually navigating your filesystem to find the source file for a flow you want to edit, you can simply run:</p> <pre><code>cx&gt; open flow my-daily-report\n</code></pre> <p>The shell understands what a \"flow\" is, finds the correct file, and opens it in your default text editor. This keeps you in the \"flow state\" of your work without context switching.</p> <p>By combining the live session with a managed library of reusable assets, the <code>cx</code> shell provides a complete, end-to-end environment for building, testing, and executing your most common operational workflows.</p>"},{"location":"concepts/thinking-in-pipelines/","title":"Concepts: Thinking in Pipelines","text":"<p>The design of the <code>cx</code> shell is deeply rooted in the UNIX philosophy, a set of design principles that have powered command-line interfaces for decades. The most important of these principles is composition:</p> <p>Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface.</p> <p>The <code>cx</code> shell adapts this for the modern data world. Instead of text streams, we use structured data (JSON), but the core idea is the same. To master <code>cx</code>, you must learn to \"think in pipelines.\"</p>"},{"location":"concepts/thinking-in-pipelines/#the-anatomy-of-a-cx-pipeline","title":"The Anatomy of a <code>cx</code> Pipeline","text":"<p>A pipeline is a chain of one or more commands linked by the pipe operator (<code>|</code>). The data flows from left to right.</p> <p><code>[SOURCE]</code> -&gt; <code>|</code> -&gt; <code>[FILTER / TRANSFORM]</code> -&gt; <code>|</code> -&gt; <code>[ACTION / SINK]</code></p>"},{"location":"concepts/thinking-in-pipelines/#1-the-source-where-data-begins","title":"1. The Source: Where Data Begins","text":"<p>Every pipeline starts with a command that produces data. This can be:</p> <ul> <li>A dot-notation command fetching data from a live API (<code>gh.getUsers()</code>).</li> <li>A <code>query run</code> command fetching data from a database.</li> <li>A <code>flow run</code> command executing a predefined workflow.</li> <li>A session variable that holds data from a previous operation (<code>my_repos</code>).</li> </ul>"},{"location":"concepts/thinking-in-pipelines/#2-the-filter-transform-shaping-the-data","title":"2. The Filter / Transform: Shaping the Data","text":"<p>This is the middle of the pipeline. These commands take data from their <code>stdin</code> (the command to the left) and transform it in some way.</p> <ul> <li><code>transform run --script ...</code>: The most powerful transformer. It executes a multi-step <code>.transformer.yaml</code> workflow on the incoming data.</li> <li><code>script run ...</code>: Executes a custom Python script on the data.</li> <li><code>--query \"...\"</code>: The universal JMESPath formatter can also be thought of as a powerful, in-line filter and shaping tool.</li> </ul>"},{"location":"concepts/thinking-in-pipelines/#3-the-sink-where-data-ends","title":"3. The Sink: Where Data Ends","text":"<p>The final command in a pipeline either displays the data or sends it to another system.</p> <ul> <li><code>--output table</code>: A formatter that acts as a \"sink,\" displaying the final data in a human-readable table.</li> <li>(Future) <code>email send ...</code>: A hypothetical action that would take the incoming data and use it to populate and send an email.</li> <li>(Future) <code>webhook post ...</code>: An action that would send the final data to a webhook URL.</li> </ul> <p>If no sink is specified, the default behavior is to print the final, transformed JSON data to the console.</p>"},{"location":"concepts/thinking-in-pipelines/#prototyping-in-the-shell","title":"Prototyping in the Shell","text":"<p>The power of the interactive shell is that it allows you to build these pipelines iteratively.</p> <ol> <li>Start with the source: <code>cx&gt; repos = gh.read(\"...\")</code></li> <li>Inspect the result: <code>cx&gt; inspect repos</code></li> <li>Add a filter: <code>cx&gt; repos --query \"content[?language=='Python']\"</code></li> <li>Add formatting: <code>cx&gt; repos --query \"content[?language=='Python']\" --output table</code></li> <li>Chain a transformation: <code>cx&gt; repos | transform run --script my-script.yaml</code></li> <li>Assign the final result: <code>cx&gt; python_repos = repos | transform ...</code></li> </ol> <p>Once you have perfected your one-liner, you can encapsulate that entire pipeline inside a <code>.flow.yaml</code> file. This process of interactive prototyping followed by persistent automation is the core workflow of the Contextually platform.</p>"},{"location":"cookbook/daily-reporting-workflow/","title":"Cookbook: Automating a Daily Report","text":"<p>This recipe demonstrates a complete, real-world workflow: fetching data from a database, transforming it into a professional Excel report and an HTML email summary, and preparing it for delivery.</p> <p>This showcases the synergy between nearly every major feature of the <code>cx</code> shell: connections, queries, variables, pipelines, and formatters.</p> <p>Goal: Create an Excel report and an HTML email body from a SQL query.</p>"},{"location":"cookbook/daily-reporting-workflow/#prerequisites","title":"Prerequisites","text":"<ol> <li>A saved <code>.sql</code> file in <code>~/.cx/queries/</code>, named <code>get-daily-txns.sql</code>:     <pre><code>-- ~/.cx/queries/get-daily-txns.sql\nSELECT *\nFROM WyndhamTransactionsReport\nWHERE booking_date &gt;= :start_date AND booking_date &lt; :end_date;\n</code></pre></li> <li> <p>A saved <code>.transformer.yaml</code> file in <code>~/.cx/flows/</code> (or any other location), named <code>build-report-artifacts.transformer.yaml</code>:</p> <pre><code># ~/.cx/flows/build-report-artifacts.transformer.yaml\nname: \"Build Daily Report Artifacts\"\nsteps:\n  - name: \"Clean and Prepare Data\"\n    engine: \"pandas\"\n    operations:\n      - type: \"rename_columns\"\n        style: \"title_case\"\n      - type: \"convert_column_types\"\n        to_naive_utc_datetimes: [\"Booking Date\", \"Transaction Timestamp\"]\n\n  - name: \"Save Formatted Excel Report\"\n    engine: \"file_format\"\n    operation:\n      type: \"save\"\n      format: \"excel\"\n      target_path: \"./outputs/daily_report_{{ query_parameters.start_date }}.xlsx\"\n      artifact_type: \"attachment\"\n      excel_formatting:\n        table_style: \"TableStyleMedium2\"\n</code></pre> </li> <li> <p>An active database connection with the alias <code>db</code>.     <pre><code>cx&gt; connect user:prod-db --as db\n</code></pre></p> </li> </ol>"},{"location":"cookbook/daily-reporting-workflow/#the-workflow-in-the-shell","title":"The Workflow in the Shell","text":"<p>Here is the entire workflow, executed as a single, powerful pipeline and assigned to a variable.</p> <pre><code>cx&gt; report = query run --on db get-daily-txns start_date=2025-09-01 end_date=2025-09-02 | transform run --script ~/.cx/flows/build-report-artifacts.transformer.yaml\n</code></pre> <p>Let's break down this command:</p> <ol> <li><code>query run --on db ...</code>: This executes our saved SQL query against the <code>db</code> connection. It passes the <code>start_date</code> and <code>end_date</code> as parameters, which SQLAlchemy safely binds to the <code>:start_date</code> and <code>:end_date</code> markers in the SQL file. The result is a JSON object: <code>{\"parameters\": {...}, \"data\": [...]}</code>.</li> <li><code>|</code>: The pipe sends this JSON object to the next stage.</li> <li><code>transform run --script ...</code>: This executes our transformer workflow.<ul> <li>The <code>TransformerService</code> intelligently unpacks the <code>data</code> array from the piped input.</li> <li>It renames the columns to \"Title Case\" and formats the dates.</li> <li>It then saves the cleaned data to a dynamically named Excel file (e.g., <code>daily_report_2025-09-01.xlsx</code>) inside a newly created <code>./outputs</code> directory.</li> <li>The service returns an \"Artifact Manifest\" as its final result.</li> </ul> </li> <li><code>report = ...</code>: The final Artifact Manifest is saved to the <code>report</code> variable.</li> </ol>"},{"location":"cookbook/daily-reporting-workflow/#inspecting-the-result","title":"Inspecting the Result","text":"<p>Now, you can inspect the <code>report</code> variable to find the path to your generated Excel file.</p> <pre><code>cx&gt; inspect report\n</code></pre> <p>The output will show a dictionary containing the path to the Excel file, which you can then open directly:</p> <pre><code>cx&gt; open {{ report.artifacts.attachments[0] }}\n</code></pre> <p>This recipe demonstrates how <code>cx</code> can orchestrate a complex, multi-stage process involving data extraction, transformation, and artifact generation in a single, readable command line. This pipeline can now be saved as its own <code>.flow.yaml</code> file for single-command execution in the future.</p>"},{"location":"cookbook/on-demand-data-api/","title":"Cookbook: Creating an On-Demand Data API","text":"<p>One of the most powerful concepts in the <code>cx</code> shell is treating your saved <code>.flow.yaml</code> files not just as scripts, but as a personal library of reusable, parameterizable functions. By creating a flow that takes arguments, you are effectively building a custom, on-demand data API for your own operational needs.</p> <p>Goal: Create a reusable flow to look up a GitHub user's profile and then use formatters to view the data in different ways.</p>"},{"location":"cookbook/on-demand-data-api/#1-the-api-endpoint-get-userflowyaml","title":"1. The \"API Endpoint\" - <code>get-user.flow.yaml</code>","text":"<p>First, we create our reusable workflow. This flow requires a <code>username</code> to be passed in via <code>script_input</code>.</p> <p>Action: Save the following content in <code>~/.cx/flows/get-user.flow.yaml</code>.</p> <pre><code># ~/.cx/flows/get-user.flow.yaml\nname: \"Get GitHub User\"\ndescription: \"Fetches the public profile for a given GitHub username.\"\nsteps:\n  - id: get_user\n    name: \"Get User from GitHub\"\n    connection_source: \"user:github\" # Assumes a 'github' connection config exists\n    run:\n      action: \"run_declarative_action\"\n      template_key: \"getUser\"\n      context:\n        # This username is provided at runtime by the 'flow run' command\n        username: \"{{ script_input.username }}\"\n</code></pre>"},{"location":"cookbook/on-demand-data-api/#2-calling-the-api-endpoint","title":"2. \"Calling\" the API Endpoint","text":"<p>Now, from within the <code>cx&gt;</code> shell, you can \"call\" this flow like a function using the <code>flow run</code> command.</p> <p>Prerequisite: You have an active GitHub connection with the alias <code>gh</code>.</p> <pre><code>cx&gt; connect user:github --as gh\n</code></pre> <p>Execution:</p> <pre><code># Call the flow for the 'microsoft' user\ncx&gt; flow run get-user username=microsoft\n</code></pre> <p>Result: The shell executes the flow, injecting <code>username=microsoft</code> into the <code>script_input</code> context. The final, raw JSON output of the <code>getUser</code> action is printed to the screen.</p>"},{"location":"cookbook/on-demand-data-api/#3-composing-with-formatters","title":"3. Composing with Formatters","text":"<p>This is where the true power emerges. Because <code>flow run</code> is a standard data-producing command, you can pipe its output to the universal formatters to reshape the data on the fly, just like you would with a real API.</p> <p>Scenario 1: View a summary as a table</p> <p>Let's say you only care about a few key details. You can run the same flow and pipe the result to a table view with selected columns.</p> <pre><code>cx&gt; flow run get-user username=microsoft --output table --query \"to_array(@.'Get User from GitHub')\" --columns key,value\n</code></pre> <ul> <li><code>--query \"...\"</code>: The JMESPath query unpacks the result from the step name (<code>Get User from GitHub</code>) and transforms the resulting dictionary into a list of key-value pairs.</li> <li><code>--output table</code>: Renders that list as a clean, two-column table.</li> </ul> <p>Scenario 2: Extract a single piece of information</p> <p>What if you only need the number of public repositories?</p> <pre><code>cx&gt; flow run get-user username=microsoft --query \"'Get User from GitHub'.public_repos\"\n</code></pre> <p>Result: The shell will print a single number: <code>7046</code> (or whatever the current count is).</p> <p>By creating a library of these small, parameterized flows, you build up a powerful set of custom tools tailored to your exact needs. You no longer need to remember complex API calls; you just need to remember the name of the flow you created.</p>"},{"location":"how-to/building-pipelines/","title":"How-To: Build In-Terminal Pipelines","text":"<p>The true power of the <code>cx</code> shell lies in its ability to compose commands into powerful, in-terminal pipelines. This follows the UNIX philosophy: have small, sharp tools that do one thing well, and chain them together to solve complex problems.</p> <p>This guide will walk you through the syntax and concepts for building pipelines, from simple data viewing to complex filtering and formatting.</p>"},{"location":"how-to/building-pipelines/#the-core-operators","title":"The Core Operators","text":"<p>Your entire workflow is built around three core operators:</p> Operator Syntax Purpose Assignment <code>=</code> Stores the output of a command or pipeline in a variable. Pipelining <code>\\|</code> Sends the output of the command on the left to the input of the command on the right. Grouping <code>(...)</code> Controls the order of operations, just like in mathematics."},{"location":"how-to/building-pipelines/#a-step-by-step-example","title":"A Step-by-Step Example","text":"<p>Let's build a pipeline to find the most popular repositories from a GitHub organization.</p>"},{"location":"how-to/building-pipelines/#step-1-get-the-raw-data","title":"Step 1: Get the Raw Data","text":"<p>First, we need to get the list of repositories. We'll connect to GitHub and use the <code>read</code> command, storing the result in a variable named <code>repos</code>.</p> <pre><code>cx&gt; connect user:github --as gh\ncx&gt; repos = gh.read(\"https://api.github.com/users/google/repos\")\n</code></pre>"},{"location":"how-to/building-pipelines/#step-2-unpack-and-view-the-data","title":"Step 2: Unpack and View the Data","text":"<p>The <code>repos</code> variable contains a wrapper object. To see the actual list of repositories, we need to unpack the data and view it as a table. This is our first simple pipeline.</p> <pre><code>cx&gt; repos --query \"content\" | --output table\n</code></pre> <ul> <li><code>repos --query \"content\"</code>: This command takes the <code>repos</code> variable, and the JMESPath query <code>content</code> extracts the value of the \"content\" key (which is our list of repository objects).</li> <li><code>|</code>: The pipe operator sends this list of objects to the next command.</li> <li><code>--output table</code>: This is a universal formatter that takes the incoming list and renders it as a table.</li> </ul>"},{"location":"how-to/building-pipelines/#step-3-filter-and-select-data","title":"Step 3: Filter and Select Data","text":"<p>The full table is too much information. Let's refine the pipeline to only show popular repositories and select specific columns.</p> <pre><code>cx&gt; repos --query \"content[?stargazers_count &gt; 20000].[name, language, stargazers_count]\" --output table --columns Name,Language,Stars\n</code></pre> <p>Let's break down this powerful one-liner:</p> <ol> <li><code>repos</code>: Starts the pipeline with our variable.</li> <li><code>--query \"...\"</code>: The JMESPath expression runs first.<ul> <li><code>content</code>: Unpacks the repository list from the <code>content</code> key.</li> <li><code>[?stargazers_count &gt; 20000]</code>: Filters this list, keeping only repositories with more than 20,000 stars.</li> <li><code>.[name, language, stargazers_count]</code>: From the filtered repos, it creates a new list containing only the values for these three keys. The result is a list of lists.</li> </ul> </li> <li><code>--output table</code>: Specifies that the final result should be a table.</li> <li><code>--columns Name,Language,Stars</code>: Provides the headers for the table, which is required when the input is a list of lists.</li> </ol>"},{"location":"how-to/building-pipelines/#step-4-grouping-for-precedence","title":"Step 4: Grouping for Precedence","text":"<p>What if you wanted to run a script on the data before formatting it? You use parentheses to group the data processing part of the pipeline.</p> <pre><code>cx&gt; (repos --query \"content\" | script run summarize-repos) --output table\n</code></pre> <p>This ensures the <code>script run</code> command completes, and then the <code>--output table</code> flag is applied to the final result of that pipeline.</p> <p>By combining variables, pipes, and formatters, you can perform complex data analysis and exploration tasks in a single, readable line without ever leaving your terminal.</p>"},{"location":"how-to/connect-database/","title":"How-To: Connect to a Database","text":"<p>One of the most powerful features of Contextually is its ability to connect to and query your SQL databases directly from the <code>cx</code> shell. This guide will walk you through the process of setting up a new connection to a Microsoft SQL Server database.</p> <p>The process for other supported databases (like PostgreSQL or Trino) is nearly identical\u2014you just need to use the correct blueprint ID.</p>"},{"location":"how-to/connect-database/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have <code>cx</code> installed.</li> <li>You have the connection details for your database: server address, database name, username, and password.</li> </ul>"},{"location":"how-to/connect-database/#step-1-find-the-right-blueprint","title":"Step 1: Find the Right Blueprint","text":"<p>The first step is to identify the correct blueprint for your database type. You can find a full list in our public Blueprint Registry.</p> <p>For this guide, we will use the official system blueprint for Microsoft SQL Server: <code>system/mssql@v0.1.1</code></p>"},{"location":"how-to/connect-database/#step-2-run-cx-connection-create","title":"Step 2: Run <code>cx connection create</code>","text":"<p>The <code>cx connection create</code> command is an interactive wizard that will guide you through the setup process. It uses the blueprint you specify to ask for exactly the right information.</p> <p>Run the following command in your terminal:</p> <pre><code>cx connection create --blueprint \"system/mssql@v0.1.1\"\n</code></pre>"},{"location":"how-to/connect-database/#step-3-follow-the-interactive-prompts","title":"Step 3: Follow the Interactive Prompts","text":"<p>The shell will now prompt you for the information defined in the <code>mssql</code> blueprint.</p> <ol> <li>Friendly Name: Give your connection a memorable name, like <code>Production Reporting DB</code>.</li> <li>Unique ID (Alias): Provide a short, command-line-friendly alias, like <code>prod-db</code>.</li> <li>Connection Details: Enter your server address, database name, username, and password when prompted.</li> </ol> <pre><code>--- Create a New Connection (Interactive) ---\nUsing blueprint: system/mssql@v0.1.1\n\nPlease provide the following details for 'Username &amp; Password':\nEnter a friendly name for this connection: Production Reporting DB\nEnter a unique ID (alias) (production-reporting-db): prod-db\n(Note: Password input will be hidden for security.)\nServer Address (hostname or IP): your-server.database.windows.net\nDatabase Name: YourDatabase\nUsername: your_username\nPassword: ***************\n</code></pre> <p>After you provide the details, <code>cx</code> will show you a preview of the files it's about to create and ask for confirmation. Press <code>y</code> to save.</p> <p>Connection Saved!</p> <p>Your connection details are now securely saved in <code>~/.cx/connections/prod-db.conn.yaml</code> and <code>~/.cx/secrets/prod-db.secret.env</code>.</p>"},{"location":"how-to/connect-database/#step-4-test-and-use-your-new-connection","title":"Step 4: Test and Use Your New Connection","text":"<p>Now you can use your new connection in the interactive shell.</p> <ol> <li> <p>Start the shell:</p> <pre><code>cx\n</code></pre> </li> <li> <p>Connect using your new alias:</p> <pre><code>cx&gt; connect user:prod-db --as db\n</code></pre> <p>You should see a <code>\u2705 Connection successful</code> message.</p> </li> <li> <p>Run a query!     You can now use the canonical <code>.query()</code> action to execute any SQL command against your database.</p> <pre><code>cx&gt; db.query(\"SELECT TOP 5 * FROM YourTable;\")\n</code></pre> </li> </ol> <p>You are now connected to your live database and can run queries, pipe results, and integrate this data source into larger Contextually workflows.</p>"},{"location":"how-to/connect-rest-api/","title":"How-To: Connect to a REST API (OAuth2)","text":"<p>Connecting to a REST API is a core function of Contextually. While many public APIs can be used without authentication (like the GitHub example in our \"Getting Started\" guide), most powerful APIs require it.</p> <p>This guide will walk you through a common and secure pattern for connecting to an API that uses OAuth2, using the Spotify blueprint as our example.</p>"},{"location":"how-to/connect-rest-api/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have <code>cx</code> installed (<code>v0.1.1</code> or later).</li> <li>You have followed the API provider's instructions to obtain your credentials. For Spotify, this means visiting their Developer Dashboard to get a Client ID and Client Secret.</li> </ul>"},{"location":"how-to/connect-rest-api/#step-1-obtain-a-refresh-token-one-time-setup","title":"Step 1: Obtain a Refresh Token (One-Time Setup)","text":"<p>OAuth2 requires a one-time, browser-based user authorization step to grant <code>cx</code> permission to act on your behalf. This process generates a long-lived Refresh Token, which is the key to all future automated interactions.</p> <p>This step is typically performed using a small helper script or a utility provided by the API developer. A detailed guide is beyond the scope of this document, but the process generally involves:</p> <ol> <li>Running a local script.</li> <li>Being redirected to your browser to log in to the service (e.g., Spotify).</li> <li>Authorizing the application.</li> <li>Being redirected back to the script, which captures the <code>refresh_token</code>.</li> </ol> <p>What to Expect</p> <p>At the end of this one-time process, you will have three critical secrets: <code>Client ID</code>, <code>Client Secret</code>, and <code>Refresh Token</code>. Keep them safe.</p>"},{"location":"how-to/connect-rest-api/#step-2-find-the-blueprint","title":"Step 2: Find the Blueprint","text":"<p>Next, identify the correct blueprint for the API. We will use the official Spotify blueprint from the public registry. You can find its ID in the Blueprint Registry README.</p> <p>For this guide, the ID is: <code>community/spotify@v0.1.0</code></p> <p>You can inspect this blueprint's <code>supported_auth_methods</code> section in its source to see the exact secret names it expects (e.g., <code>client_id</code>, <code>client_secret</code>, <code>refresh_token</code>).</p>"},{"location":"how-to/connect-rest-api/#step-3-create-the-connection-non-interactively","title":"Step 3: Create the Connection Non-Interactively","text":"<p>For connections with multiple, sensitive secret keys, the non-interactive <code>cx connection create</code> command is the most secure and efficient method. It allows you to provide the secrets directly without them being saved in your shell history.</p> <p>Construct the command in your text editor, replacing the placeholder values with your actual credentials. Then, paste and run the complete command in your terminal.</p> <pre><code>cx connection create \\\n  --name \"My Spotify Account\" \\\n  --id \"my-spotify\" \\\n  --blueprint \"community/spotify@v0.1.0\" \\\n  --secret \"client_id=YOUR_SPOTIFY_CLIENT_ID\" \\\n  --secret \"client_secret=YOUR_SPOTIFY_CLIENT_SECRET\" \\\n  --secret \"refresh_token=YOUR_LONG_LIVED_REFRESH_TOKEN\"\n</code></pre> <p>Connection Saved Securely!</p> <p>The command will create <code>~/.cx/connections/my-spotify.conn.yaml</code> for the non-sensitive data and <code>~/.cx/secrets/my-spotify.secret.env</code> for your secret tokens.</p>"},{"location":"how-to/connect-rest-api/#step-4-test-and-use-your-connection","title":"Step 4: Test and Use Your Connection","text":"<p>Now you can use your new connection in the interactive shell. <code>cx</code> will handle all future token refreshes automatically in the background.</p> <ol> <li> <p>Start the shell:</p> <pre><code>cx\n</code></pre> </li> <li> <p>Connect using your new alias:</p> <pre><code>cx&gt; connect user:my-spotify --as spotify\n</code></pre> <p>You should see a <code>\u2705 Connection successful</code> message.</p> </li> <li> <p>Run an action!     Type <code>spotify.</code> and press Tab to see all the actions available from the Spotify blueprint.</p> <pre><code>cx&gt; spotify.getListOfCurrentUserPlaylists()\n</code></pre> </li> </ol> <p>You are now connected to a live, OAuth2-protected API. The <code>cx</code> shell will manage the short-lived access tokens for you, allowing you to focus on your workflow.</p>"},{"location":"how-to/manage-processes/","title":"How-To: Manage Background Processes","text":"<p>The <code>cx</code> shell includes a powerful process manager for running long, non-interactive tasks in the background. This allows you to kick off a heavy data processing flow and immediately get your interactive prompt back, while still being able to monitor the task's progress.</p> <p>While background processes will primarily be launched by the <code>agent</code> command in the future (<code>v0.5.0</code>), you can learn to manage them now with the <code>cx process</code> command suite, available in both the CLI and the interactive REPL.</p>"},{"location":"how-to/manage-processes/#when-to-use-a-background-process","title":"When to Use a Background Process","text":"<p>A background process is ideal for any workflow that might take more than a few seconds to run, such as:</p> <ul> <li>Large database queries and data extraction jobs.</li> <li>Flows that make hundreds or thousands of API calls.</li> <li>Data transformation scripts that operate on large files.</li> </ul>"},{"location":"how-to/manage-processes/#listing-active-processes-process-list","title":"Listing Active Processes (<code>process list</code>)","text":"<p>To see all background processes you have started, use the <code>list</code> subcommand.</p> <pre><code>cx&gt; process list\n\n```\n\nThis will display a table showing the unique ID of each process, its current `Status` (`running`, `completed`, `failed`), the name of the flow it's executing, and when it was started.\n\n### Viewing Logs (`process logs`)\n\nEvery background process streams its output (both standard output and errors) to a dedicated log file in your `~/.cx/logs/` directory. You can easily view this output with the `logs` subcommand.\n\n**To view the full log of a completed or running process:**\n```\n\ncx&gt; process logs proc-20250905-01\n\n```\n\n### Tailing Live Logs (`process logs --follow`)\n\nThe most powerful feature for monitoring is the ability to \"tail\" the log file in real-time, just like the `tail -f` command in Linux. This is perfect for watching the progress of a currently running job.\n\n```\n\ncx&gt; process logs --follow proc-20250905-01\n\n```\nThe shell will display the log output as it's written. You can press `Ctrl+C` at any time to stop following the log and return to the `cx&gt;` prompt, without interrupting the background process itself.\n```\n\n---\n\n#### **File 4: `docs/tutorials/first-agent-session.md` (New File)**\n\nThis tutorial provides a gentle, hands-on introduction to the new agentic features.\n\n```markdown\n# /home/dpwanjala/repositories/flowcontextually/docs/docs/tutorials/first-agent-session.md\n\n# Tutorial: Your First Agentic Translation\n\nWelcome to the next step in your Contextually journey! You've mastered the basics of running commands; now it's time to let the `cx` shell's built-in AI do the work for you.\n\nThis tutorial will guide you through using the new **Translate feature**. You will learn how to turn your plain-English goals into precise, executable commands without needing to remember the exact syntax.\n\n**What you will learn:**\n\n- How to use the `//` directive to trigger a translation.\n- How the seamless, on-demand setup for AI providers works.\n- How to translate a complex goal involving a pipeline.\n\n### 1. Your First \"Whisper\" to `cx`\n\nThe \"Translate\" feature is triggered by starting your line with `//`, like a comment. This tells the shell, \"Don't run this; translate it for me.\"\n\nLet's try a simple one.\n```\n\ncx&gt; // show me all the applications I have installed\n\n```\n\nPress **Enter**.\n\n### 2. The One-Time Onboarding Magic\n\nIf this is the first time you've used an agentic feature, `cx` will now guide you through a one-time setup for your AI provider connection. The default is OpenAI.\n\n1.  The shell will explain that it needs an AI provider connection.\n2.  It will launch the interactive `connection create` wizard, pre-filled with the OpenAI blueprint.\n3.  Follow the prompts. You'll be asked for:\n    *   A friendly name (e.g., `My OpenAI Account`).\n    *   A unique ID (you can accept the default).\n    *   Your OpenAI API Key (starting with `sk-...`).\n4.  Confirm to save the connection.\n\nAfter you save, `cx` will automatically activate the connection for your current session and seamlessly resume your original translation request.\n\n### 3. Review and Execute\n\nAfter a brief \"Translating...\" message, the line in your prompt will be replaced with the correct command.\n\n```\n\ncx&gt; app list\n\n```\n\nThe shell has correctly translated your intent into the `app list` command. It's now waiting for your final confirmation. Press **Enter** again to run it.\n\n### 4. Translating a More Complex Goal\n\nThe real power of the Translate feature shines when you have a more complex goal. Let's assume you have a session variable named `repos` containing a list of repository data.\n\nTry translating this:\n```\n\ncx&gt; // from my repos variable, show a table of javascript repos with more than 1000 stars\n\n```\n\nPress **Enter**. The shell will translate this complex request, including the pipeline, query, and formatters, into the correct one-liner:\n```\n\ncx&gt; repos --query \"content[?language=='JavaScript' &amp;&amp; stargazers_count &gt; `1000`]\" --output table\n\n```\n\n**Congratulations!** You are now leveraging the `cx` Intent Engine to write powerful commands with ease. You can use this for any task, from simple lookups to building complex, multi-stage pipelines.\n```\n</code></pre>"},{"location":"how-to/managing-your-workspace/","title":"How-To: Manage Your Workspace","text":"<p>The <code>cx</code> interactive shell is more than just a command line\u2014it's a persistent workspace. As you work, you create valuable assets: active connections, variables holding important data, and reusable workflows. This guide will show you how to manage these assets effectively using the built-in workspace commands.</p>"},{"location":"how-to/managing-your-workspace/#understanding-your-session","title":"Understanding Your Session","text":"<p>Your \"session\" is the live, in-memory state of your <code>cx&gt;</code> prompt. It includes:</p> <ul> <li>Active Connections: Aliases you've created with <code>connect</code>.</li> <li>Session Variables: Data you've saved with the <code>=</code> operator.</li> </ul>"},{"location":"how-to/managing-your-workspace/#checking-session-status","title":"Checking Session Status","text":"<p>At any time, you can get a high-level overview of your current session with the <code>session status</code> command.</p> <pre><code>cx&gt; session status\n</code></pre> <p>This will display a clean panel showing how many connections and variables are currently active.</p>"},{"location":"how-to/managing-your-workspace/#listing-active-connections","title":"Listing Active Connections","text":"<p>To see the details of your active connections, use the <code>connections</code> command.</p> <pre><code>cx&gt; connections\n</code></pre> <p>This is useful for remembering which alias points to which data source.</p>"},{"location":"how-to/managing-your-workspace/#listing-session-variables","title":"Listing Session Variables","text":"<p>To see a detailed summary of all the data you have stored in memory, use the <code>var list</code> (or <code>vars list</code>) command.</p> <pre><code>cx&gt; var list\n</code></pre> <p>This will display a table showing each variable's name, its data type (like <code>dict</code> or <code>list</code>), its size, and a preview of its content.</p>"},{"location":"how-to/managing-your-workspace/#persisting-your-workspace-with-sessions","title":"Persisting Your Workspace with Sessions","text":"<p>Session variables are temporary; they disappear when you <code>exit</code> the shell. To save your entire workspace for later, you need to use the <code>session</code> commands.</p>"},{"location":"how-to/managing-your-workspace/#saving-a-session","title":"Saving a Session","text":"<p>The <code>session save</code> command takes a snapshot of your current state (all active connections and variables) and saves it to a file in your <code>~/.cx/sessions/</code> directory.</p> <pre><code># After setting up connections and variables...\ncx&gt; session save my-project-work\n</code></pre> <p>This creates a file named <code>my-project-work.cxsession</code>.</p>"},{"location":"how-to/managing-your-workspace/#listing-saved-sessions","title":"Listing Saved Sessions","text":"<p>Forgot what you've saved? Use <code>session list</code>.</p> <pre><code>cx&gt; session list\n</code></pre> <p>This scans your <code>~/.cx/sessions/</code> directory and shows a table of all saved sessions, including when they were last modified and their size.</p>"},{"location":"how-to/managing-your-workspace/#loading-a-session","title":"Loading a Session","text":"<p>To restore a saved workspace, start a fresh <code>cx</code> shell and use <code>session load</code>.</p> <pre><code>cx&gt; session load my-project-work\n</code></pre> <p>The shell will instantly restore all the connections and variables from that session, allowing you to pick up exactly where you left off.</p>"},{"location":"how-to/managing-your-workspace/#deleting-a-session","title":"Deleting a Session","text":"<p>Once a project is finished, you can clean up saved sessions with <code>session rm</code>.</p> <pre><code>cx&gt; session rm my-project-work\n</code></pre> <p>The shell will ask for confirmation before deleting the file.</p>"},{"location":"how-to/managing-your-workspace/#managing-your-reusable-assets","title":"Managing Your Reusable Assets","text":"<p>Beyond the live session, <code>cx</code> helps you build a personal library of reusable <code>flows</code>, <code>queries</code>, and <code>scripts</code>. These are stored as files in your <code>~/.cx/</code> directory.</p>"},{"location":"how-to/managing-your-workspace/#listing-your-assets","title":"Listing Your Assets","text":"<p>You can discover the assets you've created with the <code>list</code> subcommand for each asset type.</p> <pre><code># See all your reusable YAML workflows\ncx&gt; flow list\n\n# See all your saved SQL files\ncx&gt; query list\n\n# See all your saved Python scripts\ncx&gt; script list\n</code></pre>"},{"location":"how-to/managing-your-workspace/#editing-your-assets-with-open","title":"Editing Your Assets with <code>open</code>","text":"<p>The <code>open</code> command is a powerful bridge to your text editor. It lets you quickly open the source file for any asset without needing to find it in your file explorer.</p> <pre><code># Open a flow file in your default editor (e.g., VS Code)\ncx&gt; open flow my-data-flow\n\n# Open a saved SQL query\ncx&gt; open query get-daily-users\n</code></pre> <p>By mastering these commands, you transform the <code>cx</code> shell from a simple tool into a complete, persistent, and organized Integrated Development Environment (IDE) for your data and operations tasks.</p>"},{"location":"how-to/packaging-an-application/","title":"How-To: Package and Share an Application","text":"<p>One of the most valuable contributions you can make to the Contextually ecosystem is to package a useful workflow into a shareable Application. This guide will walk you through the process of creating a valid application package, ready for private distribution or for contribution to the public registry.</p> <p>Goal: Turn a collection of local assets into a distributable <code>.tar.gz</code> archive.</p>"},{"location":"how-to/packaging-an-application/#1-organize-your-assets","title":"1. Organize Your Assets","text":"<p>First, create a single root directory for your application. Inside this directory, organize all your assets into the standard <code>~/.cx/</code> subfolder names.</p> <p>Example Structure:</p> <pre><code>my-awesome-app/\n\u251c\u2500\u2500 flows/\n\u2502 \u2514\u2500\u2500 do-the-main-thing.flow.yaml\n\u251c\u2500\u2500 queries/\n\u2502 \u2514\u2500\u2500 get-the-data.sql\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"how-to/packaging-an-application/#2-create-the-appcxyaml-manifest","title":"2. Create the <code>app.cx.yaml</code> Manifest","text":"<p>At the root of your application directory (<code>my-awesome-app/</code>), create an <code>app.cx.yaml</code> file. This is the manifest that tells the <code>cx</code> installer what your application is and what it needs.</p> <pre><code># my-awesome-app/app.cx.yaml\nname: my-awesome-app\nnamespace: community\nversion: 1.0.0\ndescription: \"This application does one awesome thing.\"\nauthor: \"Your Name\"\n\n# List all the blueprint versions your flows/queries depend on.\ndependencies:\n  blueprints:\n    - \"system/mssql@v0.1.1\"\n\n# Define the connections the user will be prompted to create.\nrequired_connections:\n  - id: \"database\" # The logical ID used in your flows\n    description: \"A connection to the source database.\"\n    blueprint: \"system/mssql@v0.1.1\" # The suggested blueprint\n</code></pre>"},{"location":"how-to/packaging-an-application/#3-write-a-readmemd","title":"3. Write a README.md","text":"<p>Create a README.md file in your application's root. This is crucial! The content of this file will be displayed in the user's terminal after they successfully install your application. Your README.md should briefly explain: What the application does. What flows are now available. How to run the main flow, including an example.</p>"},{"location":"how-to/packaging-an-application/#4-package-your-application","title":"4. Package Your Application","text":"<p>Once your directory is structured and your manifest is complete, you can use the cx shell to create the distributable archive. Navigate your terminal outside your application directory, and run the package command: code Bash</p> <p>This command will read <code>my-awesome-app/app.cx.yaml</code> and create <code>my-awesome-app-v1.0.0.tar.gz</code> in your current directory.</p> <pre><code>cx app package ./my-awesome-app\n</code></pre> <p>Package Created!</p> <p>You now have a .tar.gz file that can be installed by any cx user via cx app install . 5. (Optional) Contribute to the Public Registry If you'd like to make your application available to the entire community, you can submit it to the flowcontextually/applications repository by opening a Pull Request."},{"location":"how-to/use-the-agent/","title":"How-To: Use the <code>cx</code> Agent","text":"<p>The <code>cx</code> shell's integrated agentic capabilities can dramatically accelerate your workflows, from generating complex commands in an instant to solving multi-step problems autonomously. This guide will show you how to leverage both modes of the <code>cx</code> Intent Engine.</p>"},{"location":"how-to/use-the-agent/#prerequisites","title":"Prerequisites","text":"<p>To use the agentic features, you need a connection to a Large Language Model (LLM) provider. The agent is provider-agnostic, but the default configuration is set up for OpenAI.</p> <p>If you haven't already, you will need an API key from an LLM provider. The first time you use an agentic feature, <code>cx</code> will guide you through a seamless, one-time setup wizard to configure your connection.</p>"},{"location":"how-to/use-the-agent/#fast-path-instant-translation-with","title":"Fast Path: Instant Translation with <code>//</code>","text":"<p>The fastest way to use the agent is with the \"Translate\" feature. This allows you to write a goal in plain English, and <code>cx</code> will translate it into a precise, executable command for you. It's perfect for learning the shell's syntax or for commands you don't use often.</p> <ol> <li> <p>Start the <code>cx</code> shell.</p> </li> <li> <p>Write your goal as a comment. Start the line with <code>//</code> and describe what you want to do.</p> <pre><code>cx&gt; // list all my saved SQL queries\n</code></pre> </li> <li> <p>Press Enter.</p> <ul> <li>If it's your first time, the one-time setup wizard for your LLM provider will launch.</li> <li>The shell will show a \"Translating...\" status.</li> <li>The line you just typed will be replaced in-place with the correct <code>cx</code> command.</li> </ul> <pre><code>cx&gt; query list\n</code></pre> <p>The command is now in your prompt, ready for you to review, edit, or execute.</p> </li> <li> <p>Press Enter again to run the command.</p> </li> </ol>"},{"location":"how-to/use-the-agent/#deliberate-path-solving-problems-with-agent","title":"Deliberate Path: Solving Problems with <code>agent</code>","text":"<p>For more complex, multi-step tasks, you can engage the full reasoning engine with the <code>agent</code> command. This initiates a collaborative, turn-by-turn session where the agent formulates a plan and executes it with your approval.</p> <p>Example: Onboarding a new API Blueprint</p> <p>Let's ask the agent to perform a common, multi-step task: compiling a new blueprint for the Spotify API.</p> <ol> <li> <p>Invoke the agent with a high-level goal.</p> <pre><code>cx&gt; agent \"Onboard the Spotify API. The OpenAPI spec is at https://.../openapi.yaml\"\n</code></pre> </li> <li> <p>The agent presents its plan. The Planner agent analyzes your goal and creates a high-level strategy using <code>cx</code> meta-commands.</p> <pre><code>                                 Agent Plan\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502  Status  \u2502 Step                                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Pending  \u2502 1. Use the `compile` command to generate a blueprint from the    \u2502\n\u2502          \u2502    provided URL.                                                 \u2502\n\u2502 Pending  \u2502 2. Use the `connection create` command to set up a new           \u2502\n\u2502          \u2502    connection for the newly created blueprint.                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> </li> <li> <p>The agent executes the plan step-by-step. The Tool Specialist agent now takes over, generating the precise command for the first step and presenting it for your approval.</p> <pre><code>Executing Step 1: Use the `compile` command...\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Agent Plan \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Reasoning: The active step is to compile the blueprint. I will use the URL      \u2502\n\u2502 from the original goal...                                                       \u2502\n\u2502                                                                                 \u2502\n\u2502 Next Command:                                                                   \u2502\n\u2502 &gt; compile --spec-url https://.../openapi.yaml --name spotify --version 1.0.0    \u2502\n\u2502                                                                                 \u2502\n\u2502 \ud83e\uddbe Dry Run Preview:                                                             \u2502\n\u2502    \u2713 Command is syntactically valid.                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nExecute? [Yes/no/edit]:\n</code></pre> </li> <li> <p>Confirm and Collaborate. You press <code>yes</code>, the command runs, and the agent proceeds to the next step, continuing this loop until the mission is accomplished.</p> </li> </ol> <p>This powerful, deliberate reasoning mode enables <code>cx</code> to act as a true intelligent assistant for your most critical operational tasks.</p>"},{"location":"includes/installation/","title":"Installation","text":"<p>Download and install the latest pre-compiled binary for your operating system from our GitHub Releases page.</p> <p>Linux</p> <pre><code># This script downloads the latest Linux binary, extracts it, and moves it to your path.\ncurl -sL https://github.com/flowcontextually/cx-shell/releases/download/v0.1.0/cx-v0.1.0-linux-x86_64.tar.gz | tar -xz\nsudo mv cx /usr/local/bin/\ncx --version\n</code></pre> <p>macOS (Intel)</p> <pre><code># This script downloads the latest macOS (Intel) binary, extracts it, and moves it to your path.\ncurl -sL https://github.com/flowcontextually/cx-shell/releases/download/v0.1.0/cx-v0.1.0-macos-x86_64.tar.gz | tar -xz\nsudo mv cx /usr/local/bin/\ncx --version\n</code></pre> <p>macOS (Apple Silicon)</p> <p>Warning: A native Apple Silicon build is not yet available. You can run the Intel version via Rosetta 2 using the macOS (Intel) instructions.</p> <p>Windows (PowerShell)</p> <pre><code># This script downloads the latest Windows binary and unzips it.\n$url = \"https://github.com/flowcontextually/cx-shell/releases/download/v0.1.0/cx-v0.1.0-windows-amd64.zip\"\n$output = \"cx.zip\"\nInvoke-WebRequest -Uri $url -OutFile $output\nExpand-Archive -Path $output -DestinationPath .\n\n# You should now have `cx.exe` in the current directory.\n# For system-wide access, move `cx.exe` to a directory in your system's PATH.\n./cx.exe --version\n</code></pre>"},{"location":"reference/blueprint-spec/","title":"Reference: Blueprint Specification","text":"<p>A <code>blueprint.cx.yaml</code> file is the executable heart of a blueprint package. It is a declarative YAML document that defines how the Contextually runtime engine should interact with an external service.</p> <p>This document serves as the technical reference for all valid keys.</p>"},{"location":"reference/blueprint-spec/#top-level-keys","title":"Top-Level Keys","text":"<p>The following keys are the top-level attributes of a <code>blueprint.cx.yaml</code> file.</p> Key Type Required Description <code>id</code> String Yes A unique identifier for the blueprint, e.g., <code>blueprint:system-mssql</code>. <code>name</code> String Yes The human-readable name of the API, e.g., \"Microsoft SQL Server\". <code>version</code> String Yes The semantic version of this blueprint package, e.g., <code>0.2.1</code>. This must match the release tag. <code>connector_provider_key</code> String Yes The key for the runtime strategy to use, e.g., <code>rest-declarative</code>, <code>sql-mssql</code>. <code>supported_auth_methods</code> List No A list of authentication methods this blueprint supports. This contract drives the <code>cx connection create</code> wizard. <code>browse_config</code> Object Yes The core configuration for API interaction, including the base URL and action templates. <code>test_connection_config</code> Object No An optional dictionary defining how to test a connection to this service. <code>oauth_config</code> Object No Configuration for the <code>oauth2-declarative</code> provider, such as the <code>token_url</code>."},{"location":"reference/blueprint-spec/#supported_auth_methods","title":"<code>supported_auth_methods</code>","text":"<p>This section is a list of objects, where each object defines a complete, self-contained authentication method that a blueprint supports. This contract is what drives the interactive <code>cx connection create</code> command.</p>"},{"location":"reference/blueprint-spec/#supportedauthmethod-object","title":"SupportedAuthMethod Object","text":"Key Type Required Description <code>type</code> String Yes A unique identifier for this method within the blueprint (e.g., <code>credentials</code>). <code>display_name</code> String Yes A human-friendly name shown to the user (e.g., \"Username &amp; Password\"). <code>fields</code> List Yes A list of <code>AuthField</code> objects that must be collected from the user."},{"location":"reference/blueprint-spec/#authfield-object","title":"AuthField Object","text":"Key Type Required Description <code>name</code> String Yes The key for this field (e.g., <code>server</code>, <code>api_key</code>). <code>label</code> String Yes The human-friendly prompt for this field (e.g., \"Server Address\"). <code>type</code> <code>detail</code> | <code>secret</code> Yes <code>detail</code> is stored in <code>.conn.yaml</code>, <code>secret</code> is stored in <code>.secret.env</code>. <code>is_password</code> Boolean No If <code>true</code>, the interactive CLI prompt will mask the user's input. Defaults to <code>false</code>."},{"location":"reference/blueprint-spec/#example","title":"Example","text":"<pre><code>supported_auth_methods:\n  - type: credentials\n    display_name: \"Username &amp; Password\"\n    fields:\n      - name: server\n        label: \"Server Address (hostname or IP)\"\n        type: detail\n      - name: database\n        label: \"Database Name\"\n        type: detail\n      - name: username\n        label: \"Username\"\n        type: secret\n      - name: password\n        label: \"Password\"\n        type: secret\n        is_password: true\n</code></pre>"},{"location":"reference/blueprint-spec/#browse_config","title":"<code>browse_config</code>","text":"<p>This is the most important section of the blueprint for REST APIs. It defines the API's base URL and all the available actions.</p> Key Type Required Description <code>base_url_template</code> String Yes The base URL for all API calls, e.g., <code>https://api.example.com/v2</code>. <code>action_templates</code> Object Yes A dictionary where each key is a user-facing action name mapping to an action object."},{"location":"reference/blueprint-spec/#action_templates","title":"<code>action_templates</code>","text":"<p>Each key under <code>action_templates</code> is a unique, user-facing verb (often the <code>operationId</code> from an OpenAPI spec). The value is an object defining how to execute that action.</p> Key Type Required Description <code>http_method</code> String Yes (for REST) The HTTP method for the request (e.g., <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>). <code>api_endpoint</code> String Yes (for REST) The URL path for the action, relative to <code>base_url_template</code>. May contain Jinja2 variables from the flow's <code>context</code>, e.g., <code>/pets/{{ context.petId }}</code>. <code>payload_constructor</code> Object No For <code>POST</code> or <code>PUT</code> requests, this block defines the Pydantic model used to construct and validate the request body from the flow's <code>context</code>. <code>run</code> Object No For non-REST actions (like SQL), this block explicitly defines the action to execute. e.g., <code>run: { action: \"run_sql_query\" }</code>."},{"location":"reference/blueprint-spec/#payload_constructor-v021","title":"<code>payload_constructor</code> (v0.2.1+)","text":"<p>This block is the heart of the declarative payload engine. It tells the engine how to build and validate the JSON body for a request.</p> Key Type Required Description <code>_model</code> String Yes The fully-qualified name of the Pydantic model in <code>schemas.py</code> that represents the final API payload (e.g., <code>schemas.SendGridMailPayload</code>). The engine will use this to validate the <code>context</code> from the flow step before making the call. <p>Schema-Driven Transformation</p> <p>The <code>cx</code> engine is intelligent. It uses the target Pydantic model (<code>_model</code>) to automatically transform the data provided in a flow's <code>context</code>. For example, if a model field is <code>to: List[EmailObject]</code> and the user provides a simple list of strings, the engine will automatically convert it to the required <code>[{'email': '...'}]</code> structure. This keeps flow files simple and blueprints clean.</p>"},{"location":"reference/blueprint-spec/#rest-api-example","title":"REST API Example","text":"<pre><code>browse_config:\n  base_url_template: https://api.example.com/v1\n  action_templates:\n    # A GET action with a dynamic path parameter from the context.\n    getUser:\n      http_method: GET\n      api_endpoint: /users/{{ context.userId }}\n\n    # A POST action with a request body.\n    # The flow's 'context' block must provide data that can be\n    # validated against the 'schemas.User' Pydantic model.\n    createUser:\n      http_method: POST\n      api_endpoint: /users\n      payload_constructor:\n        _model: schemas.User\n</code></pre>"},{"location":"reference/blueprint-spec/#sql-example","title":"SQL Example","text":"<pre><code>browse_config:\n  action_templates:\n    query:\n      run:\n        action: \"run_sql_query\"\n      description: \"Executes a SQL query against the connected database.\"\n</code></pre>"},{"location":"reference/cli/","title":"Reference: CLI Commands (<code>$</code>)","text":"<p>This document is the official reference for the <code>cx</code> command-line interface. These commands are run from your standard operating system terminal (like Bash or PowerShell) and are primarily used for setup, automation, and non-interactive workflows.</p> <p>Looking for the Interactive Shell?</p> <p>For a detailed guide to the powerful interactive REPL (<code>cx&gt;</code>), including pipelines, variables, and session management, please see the Interactive Shell (REPL) Reference.</p>"},{"location":"reference/cli/#global-options","title":"Global Options","text":"<p>These options can be used with the top-level <code>cx</code> command or any of its subcommands.</p> Option Description <code>--help</code> Show help messages for any command. <code>--verbose</code>, <code>-v</code> Enable verbose DEBUG logging for detailed tracebacks."},{"location":"reference/cli/#top-level-commands","title":"Top-Level Commands","text":"Command Description <code>cx</code> Starts the interactive REPL (<code>cx&gt;</code>). <code>cx init</code> Initializes the <code>~/.cx</code> workspace directory. This is the recommended first step for all new users. <code>cx compile &lt;src&gt; [opts]</code> Compiles an API specification (like OpenAPI) into a Contextually blueprint package."},{"location":"reference/cli/#command-group-cx-connection","title":"Command Group: <code>cx connection</code>","text":"<p>Manages the connection configuration files stored in <code>~/.cx/connections/</code>.</p> Command Description <code>cx connection list</code> Lists all locally saved connection configuration files. <code>cx connection create [opts]</code> Creates a new connection file. Run without options for an interactive wizard, or provide flags for non-interactive creation."},{"location":"reference/cli/#command-groups-cx-extract-cx-transform","title":"Command Groups: <code>cx extract</code> &amp; <code>cx transform</code>","text":"<p>These commands are the workhorses for automated scripting. They are designed to be used with standard OS pipes (<code>|</code>) to chain workflows together.</p> Command Example Usage Description <code>cx extract run</code> <code>... \\| cx extract run --script get-data.yaml</code> Executes a declarative <code>.connector.yaml</code> script. <code>cx transform run</code> <code>... \\| cx transform run --script shape-data.yaml</code> Executes a declarative <code>.transformer.yaml</code> script, transforming data from stdin."},{"location":"reference/cli/#command-group-cx-app","title":"Command Group: <code>cx app</code>","text":"<p>Manages the entire lifecycle of Contextually Applications.</p> Command Description <code>cx app search [query]</code> Searches the public registry for available applications. <code>cx app list</code> Lists all applications currently installed in your local <code>~/.cx</code> workspace. <code>cx app install &lt;id\\|url&gt;</code> Installs an application from the public registry or a private URL, including an interactive setup wizard. <code>cx app uninstall &lt;id&gt;</code> Safely removes an application and all of its associated assets. <code>cx app sync</code> Checks for and installs any missing blueprint dependencies for all installed applications. <code>cx app package</code> (For Developers) Packages a local application directory into a distributable <code>.tar.gz</code> archive."},{"location":"reference/cli/#command-group-cx-process","title":"Command Group: <code>cx process</code>","text":"<p>Manages long-running, asynchronous background tasks, typically initiated by the <code>agent</code>.</p> Command Description <code>cx process list</code> Lists all background processes and their current status. <code>cx process logs &lt;id&gt;</code> Shows the complete log output for a specific process. <code>cx process logs --follow</code> Attaches to a running process to stream its log output in real-time. <code>cx process stop &lt;id&gt;</code> (Coming in v0.5.0) Forcibly stops a running background process."},{"location":"reference/power-tools/","title":"Reference: Power User Tools","text":"<p>The <code>cx</code> interactive shell integrates two powerful, industry-standard tools for templating and data manipulation: Jinja2 and JMESPath. Mastering these is the key to unlocking the full potential of the shell.</p>"},{"location":"reference/power-tools/#templating-with-jinja2","title":"Templating with Jinja2","text":"<p>Anywhere you can provide a string value in a <code>cx</code> command\u2014such as a parameter in a dot-notation action or an asset name\u2014you can use Jinja2 templating syntax (<code>{{ ... }}</code>).</p> <p>The shell automatically makes all of your current session variables available within the template context.</p>"},{"location":"reference/power-tools/#common-use-cases","title":"Common Use Cases","text":"<p>1. Using a Value from a Variable: This is the most common use case. After storing the result of one command, you can use its values to drive the next one.</p> <pre><code># Store the Microsoft organization profile in a variable\ncx&gt; msft = gh.getUser(username=\"microsoft\")\n\n# Inspect the variable to find the 'repos_url' key\ncx&gt; inspect msft\n\n# Use that key in the next command to fetch the repositories\ncx&gt; repos = gh.read(\"{{ msft['Get User from GitHub'].repos_url }}\")\n</code></pre> <p>2. Dynamic File Paths: You can construct file paths dynamically, which is useful in scripts.</p> <pre><code>cx&gt; filename = \"daily-report-2025-09-03.xlsx\"\n\n# The 'save' command is a future feature, but this demonstrates the concept.\ncx&gt; my_data | save --path \"./reports/{{ filename }}\"\n</code></pre> <p>For a complete guide to Jinja2 syntax, please refer to the official Jinja2 documentation.</p>"},{"location":"reference/power-tools/#filtering-and-reshaping-with-jmespath","title":"Filtering and Reshaping with JMESPath","text":"<p>The universal <code>--query</code> flag allows you to apply a JMESPath expression to the final result of any command or pipeline before it is rendered. This is an incredibly powerful tool for drilling down into complex JSON data without leaving the shell.</p> <p>The query operates on the unpacked data payload. For example, after running <code>gh.read(...)</code>, the query runs on the array of repository objects, not the <code>VfsFileContentResponse</code> wrapper.</p>"},{"location":"reference/power-tools/#common-use-cases_1","title":"Common Use Cases","text":"<p>Assume we have a variable <code>repos</code> which contains the list of repository objects from the GitHub API.</p> <p>1. Filtering a List: Get a list of repositories that have more than 20,000 stargazers. The <code>?</code> operator is the filter expression.</p> <pre><code>cx&gt; repos --query \"[?stargazers_count &gt; `20000`]\"\n</code></pre> <p>2. Selecting Specific Keys (Projection): From the filtered list, create a new list of objects containing only the <code>name</code> and <code>language</code>.</p> <pre><code>cx&gt; repos --query \"[?stargazers_count &gt; `20000`].[name, language]\"\n</code></pre> <p>Note</p> <p>When you project a list of keys like this, the result is a list of lists. To render this as a table, you must provide headers with the <code>--columns</code> flag: <code>... --output table --columns Name,Language</code></p> <p>3. Reshaping a Dictionary: The <code>to_array(@)</code> function is a powerful trick to turn a single dictionary into a list of key-value pairs, perfect for viewing in a table.</p> <pre><code># Get a single object\ncx&gt; msft_profile = flow run get-user-flow username=microsoft\n\n# View it as a key-value table\ncx&gt; msft_profile --output table --query \"to_array(@)\"\n</code></pre> <p>For a complete guide to JMESPath syntax and functions, please see the official JMESPath Tutorial.</p>"},{"location":"reference/repl/","title":"Reference: Interactive Shell (cx&gt;)","text":"<p>The <code>cx</code> interactive shell (REPL) is a powerful, stateful environment for exploring APIs, managing workspace assets, and building data workflows. This document is the definitive reference for its language and syntax, used at the <code>cx&gt;</code> prompt.</p> <p>Looking for Setup or Scripting Commands?</p> <p>For a guide to the non-interactive CLI commands like <code>cx init</code>, <code>cx compile</code>, and running automated scripts from your OS terminal, please see the CLI Commands Reference.</p>"},{"location":"reference/repl/#core-syntax-operators","title":"Core Syntax &amp; Operators","text":"Syntax Example Description <code>// &lt;prompt&gt;</code> <code>// list my flows</code> Translate a natural language prompt into a <code>cx</code> command. <code>&lt;alias&gt;.&lt;action&gt;(...)</code> <code>gh.getUser(name=\"google\")</code> Execute a blueprint-defined action on an active connection. <code>&lt;var&gt; = &lt;command&gt;</code> <code>repos = gh.read(...)</code> Assign the result of a command or pipeline to a session variable. <code>&lt;cmd&gt; \\| &lt;cmd&gt;</code> <code>flow run ... \\| script run ...</code> Pipe the output of one command to the input of the next. <code>(...)</code> <code>(repos \\| script run ...) --output table</code> Group commands to control the order of operations and precedence."},{"location":"reference/repl/#universal-output-formatters","title":"Universal Output Formatters","text":"<p>These flags can be added to the end of any data-producing command or pipeline to control how the final result is displayed.</p> Flag Example Description <code>--output table</code> <code>... --output table</code> Renders the output as a formatted table (if the data is a list of objects). <code>--columns &lt;cols&gt;</code> <code>... --output table --columns name,id</code> Selects specific columns for table view. <code>--query &lt;expr&gt;</code> <code>... --query \"[?stars &gt; 100]\"</code> Filters or reshapes data using a JMESPath expression before rendering."},{"location":"reference/repl/#workspace-management-commands","title":"Workspace Management Commands","text":"<p>These commands allow you to manage your entire workspace without leaving the shell.</p> <p>Command Aliases</p> <p>Many commands have short aliases for convenience (e.g., <code>var list</code> can also be <code>vars list</code>). The reference shows the primary form.</p> <code>session</code>: Manage persistent workspace sessions. Command Description <code>session list</code> Lists all saved session files from <code>~/.cx/sessions</code>. <code>session save &lt;name&gt;</code> Saves the current session (active connections and variables) to a file. <code>session load &lt;name&gt;</code> Replaces the current session with a saved one. <code>session rm &lt;name&gt;</code> Deletes a saved session file. <code>session status</code> Displays a summary of the current in-memory session. <code>var</code> / <code>vars</code>: Manage in-memory session variables. Command Description <code>var list</code> Lists all variables in the current session with a summary table. <code>var rm &lt;name&gt;</code> Deletes a variable from the current session. <code>flow</code>: Manage reusable <code>.flow.yaml</code> workflows. Command Description <code>flow list</code> Lists all available flows from <code>~/.cx/flows/</code>. <code>flow run &lt;name&gt; [key=value ...]</code> Executes a flow, passing arguments to its <code>script_input</code>. <code>query</code>: Manage reusable <code>.sql</code> queries. Command Description <code>query list</code> Lists all available queries from <code>~/.cx/queries/</code>. <code>query run --on &lt;alias&gt; &lt;name&gt; [key=value ...]</code> Executes a query on an active connection. <code>script</code>: Manage reusable <code>.py</code> scripts. Command Description <code>script list</code> Lists all available scripts from <code>~/.cx/scripts/</code>. <code>script run &lt;name&gt; [key=value ...]</code> Executes a Python script. <code>connection</code>: Manage connection configuration files. Command Description <code>connection list</code> Lists all saved connection configuration files. <code>connection create --blueprint \"&lt;id&gt;\"</code> Starts an interactive wizard to create a new connection file. <code>open</code>: Open workspace assets in external applications. Command Description <code>open &lt;type&gt; [name]</code> Opens an asset (e.g., <code>open flow my-flow</code>). Types: <code>flow</code>, <code>query</code>, <code>script</code>, <code>connection</code>, <code>config</code>. <code>open {{ url_variable }}</code> Opens a URL from a variable in a web browser. <code>... --in &lt;handler&gt;</code> (Optional) Opens with a specific handler (e.g., <code>--in vscode</code>). <code>inspect</code>: Introspect session variables. Command Description <code>inspect &lt;variable&gt;</code> Displays a detailed summary panel of a session variable. <code>app</code>: Discover and manage installable applications. Command Description <code>app list</code> Lists all applications currently installed in your workspace. <code>app install &lt;id\\|url&gt;</code> Installs a new application from the public registry or a private URL. <code>app uninstall &lt;id&gt;</code> Uninstalls an application and removes its assets. <code>app sync</code> Refreshes and installs any missing blueprint dependencies for all your applications. <code>agent</code>: Engage the Collaborative Agent. Command Description <code>agent &lt;goal&gt;</code> Starts a collaborative, multi-step reasoning session to achieve a complex goal. <code>process</code>: Manage background processes. Command Description <code>process list</code> Lists all background processes and their current status. <code>process logs &lt;id&gt;</code> Shows the complete log output for a specific process. <code>process logs --follow &lt;id&gt;</code> Attaches to a running process to stream its logs in real-time."},{"location":"tutorials/compiling-a-blueprint/","title":"Tutorial: Compiling Your First Blueprint","text":"<p>In the \"Getting Started\" tutorial, you used a pre-existing blueprint for the Petstore API. But the true power of Contextually comes from its ability to onboard any API with a machine-readable specification.</p> <p>This tutorial will guide you through using the <code>cx compile</code> command to automatically generate a complete, working blueprint from a public OpenAPI specification.</p> <p>What you will learn:</p> <ul> <li>How to use the <code>cx compile</code> command.</li> <li>How to inspect the artifacts generated by the compiler.</li> <li>How to use your new, locally-compiled blueprint in the interactive shell.</li> </ul>"},{"location":"tutorials/compiling-a-blueprint/#1-find-an-api-specification","title":"1. Find an API Specification","text":"<p>The <code>cx compile</code> command needs a source specification to work from. For this tutorial, we'll use the JSONPlaceholder API, a simple and free fake REST API perfect for testing.</p> <p>Its OpenAPI specification is available at this URL: <code>https://jsonplaceholder.typicode.com/openapi.json</code></p>"},{"location":"tutorials/compiling-a-blueprint/#2-run-the-cx-compile-command","title":"2. Run the <code>cx compile</code> Command","text":"<p>Now, let's feed that URL to the compiler. The <code>cx compile</code> command takes the source URL (or a local file path) and a few flags to define the new blueprint package.</p> <p>Run the following command in your terminal. We don't need to specify an <code>--output</code> directory, as <code>cx</code> will correctly default to your <code>~/.cx/blueprints</code> folder.</p> <pre><code>cx compile https://jsonplaceholder.typicode.com/openapi.json \\\n  --name jsonplaceholder \\\n  --version v1.0.0 \\\n  --namespace user\n</code></pre> <p>Let's break down the flags:</p> <ul> <li><code>--name</code>: The machine-friendly name for our blueprint.</li> <li><code>--version</code>: The semantic version for this blueprint package.</li> <li><code>--namespace</code>: We are compiling this into our <code>user</code> namespace, which is the correct place for personal and experimental blueprints.</li> </ul> <p>Compilation Successful</p> <p>You should see a <code>\u2705 Compilation Successful</code> message, indicating that the blueprint package was created in <code>~/.cx/blueprints/user/jsonplaceholder/v1.0.0/</code>.</p>"},{"location":"tutorials/compiling-a-blueprint/#3-inspect-the-generated-artifacts","title":"3. Inspect the Generated Artifacts","text":"<p>Navigate to the new directory and see what the compiler created for you:</p> <pre><code>tree ~/.cx/blueprints/user/jsonplaceholder/v1.0.0\n</code></pre> <p>You will see three key files:</p> <ul> <li><code>source_spec.json</code>: An exact copy of the original OpenAPI spec for auditability.</li> <li><code>schemas.py</code>: A Python file containing Pydantic models for all the data structures (like <code>Post</code>, <code>Comment</code>, <code>User</code>) and parameters defined in the API.</li> <li><code>blueprint.cx.yaml</code>: The executable heart of the blueprint. It contains the base URL and a list of <code>action_templates</code> automatically generated from the API's paths, like <code>getPosts</code> and <code>createPost</code>.</li> </ul>"},{"location":"tutorials/compiling-a-blueprint/#4-use-your-new-blueprint","title":"4. Use Your New Blueprint","text":"<p>Your new blueprint is now ready to be used.</p> <p>First, create a connection file that points to your new blueprint.</p> <pre><code># Create the file in your connections directory\ntouch ~/.cx/connections/jsonplaceholder.conn.yaml\n\n# Add the following content to the file\necho '\nname: \"JSONPlaceholder API\"\nid: \"user:jsonplaceholder\"\napi_catalog_id: \"user/jsonplaceholder@v1.0.0\"\nauth_method_type: \"none\"\n' &gt; ~/.cx/connections/jsonplaceholder.conn.yaml\n</code></pre> <p>Now, start the shell and use it!</p> <pre><code>cx\n</code></pre> <p>Inside the shell, connect to your new API and run an action from its blueprint:</p> <pre><code># Connect with the alias 'jph'\ncx&gt; connect user:jsonplaceholder --as jph\n\n# Run the 'getPosts' action, which was generated by the compiler!\ncx&gt; jph.getPosts()\n</code></pre> <p>Congratulations! You have successfully onboarded a brand new API onto the Contextually platform with a single command and are now interacting with it dynamically. This is the core workflow for expanding the Blueprint Ecosystem.</p>"},{"location":"tutorials/getting-started/","title":"Getting Started with Contextually","text":"<p>Welcome! This tutorial is the best place to start your journey with Contextually. In the next five minutes, you will:</p> <ol> <li>Install the <code>cx</code> command-line shell (v0.5.1).</li> <li>Initialize a sample project on your local machine.</li> <li>Use the interactive shell to connect to the public GitHub API.</li> <li>Run an API command and store its result in a session variable.</li> <li>Inspect the data you've fetched.</li> <li>Use your variable to run a second command.</li> <li>Format the final output as a table.</li> <li>Save your session for later use.</li> </ol> <p>Let's begin!</p>"},{"location":"tutorials/getting-started/#1-installation","title":"1. Installation","text":"<p>Download and install the latest <code>v0.5.1</code> pre-compiled binary for your operating system from our GitHub Releases page.</p> LinuxmacOS (Intel &amp; Apple Silicon)Windows (PowerShell) <pre><code># This script downloads the latest v0.5.1 Linux binary and moves it to your path.\ncurl -sL https://github.com/flowcontextually/cx-shell/releases/download/v0.5.1/cx-v0.5.1-linux-x86_64.tar.gz | tar -xz\nsudo mv cx /usr/local/bin/\ncx --version\n</code></pre> <pre><code># This script downloads the latest v0.5.1 macOS binary and moves it to your path.\ncurl -sL https://github.com/flowcontextually/cx-shell/releases/download/v0.5.1/cx-v0.5.1-macos-x86_64.tar.gz | tar -xz\nsudo mv cx /usr/local/bin/\ncx --version\n</code></pre> <pre><code># This script downloads the latest v0.5.1 Windows binary and unzips it.\n$url = \"https://github.com/flowcontextually/cx-shell/releases/download/v0.5.1/cx-v0.5.1-windows-amd64.zip\"\n$output = \"cx.zip\"\nInvoke-WebRequest -Uri $url -OutFile $output\nExpand-Archive -Path $output -DestinationPath .\n# We recommend moving `cx.exe` to a directory in your system's PATH for system-wide access.\n./cx.exe --version\n</code></pre> <p>Success!</p> <p>If the <code>cx --version</code> command prints a version number, you have successfully installed the Contextually Shell.</p>"},{"location":"tutorials/getting-started/#2-initialize-your-environment","title":"2. Initialize Your Environment","text":"<p>The <code>cx init</code> command creates a hidden <code>~/.cx</code> directory and populates it with essential configuration and a sample \"GitHub API\" project.</p> <pre><code>cx init\n</code></pre>"},{"location":"tutorials/getting-started/#3-start-the-interactive-shell","title":"3. Start the Interactive Shell","text":"<p>The <code>cx</code> shell is a stateful session where you can explore APIs and build workflows.</p> <pre><code>cx\n</code></pre> <p>Your terminal prompt will change to <code>cx&gt;</code>, indicating you are in the interactive shell.</p>"},{"location":"tutorials/getting-started/#4-connect-to-the-api","title":"4. Connect to the API","text":"<p>Use the <code>connect</code> command to activate the sample GitHub connection and give it the short alias <code>gh</code> for this session.</p> <pre><code>cx&gt; connect user:github --as gh\n</code></pre> <p>You will see a <code>\u2705 Connection successful</code> message.</p>"},{"location":"tutorials/getting-started/#5-fetch-data-and-store-it-in-a-variable","title":"5. Fetch Data and Store it in a Variable","text":"<p>Now, let's run an API command. We'll get the public profile for the Microsoft organization and save the result to a new session variable named <code>msft</code>.</p> <pre><code>cx&gt; msft = gh.getUser(username=\"microsoft\")\n</code></pre> <p>The shell will show a confirmation: <code>\u2713 Variable 'msft' set.</code>. The data is now stored in your session's memory.</p>"},{"location":"tutorials/getting-started/#6-inspect-your-data","title":"6. Inspect Your Data","text":"<p>How do you know what's in the <code>msft</code> variable? Use the <code>inspect</code> command.</p> <pre><code>cx&gt; inspect msft\n</code></pre> <p>You will see a formatted panel showing you that <code>msft</code> is a dictionary, its length, and all of its available keys (<code>login</code>, <code>id</code>, <code>repos_url</code>, etc.). This is how you discover the data available to you.</p>"},{"location":"tutorials/getting-started/#7-use-your-variable-to-run-another-command","title":"7. Use Your Variable to Run Another Command","text":"<p>Now, let's use the <code>repos_url</code> we discovered in the <code>msft</code> variable to fetch the list of Microsoft's public repositories. We will use Jinja2 templating to inject the value.</p> <pre><code>cx&gt; repos = gh.read(\"{{ msft['Get User from GitHub'].repos_url }}\")\n</code></pre> <p>This runs the <code>read</code> command and stores the massive list of repositories in a new variable called <code>repos</code>.</p>"},{"location":"tutorials/getting-started/#8-format-your-final-output","title":"8. Format Your Final Output","text":"<p>Printing the raw <code>repos</code> variable would be overwhelming. Let's use the universal output formatter to create a clean, readable table of the most popular repositories.</p> <pre><code>cx&gt; repos --output table --query \"content[?stargazers_count &gt; 40000].[name, language, stargazers_count]\"\n</code></pre> <p>Congratulations! You should see a beautifully formatted table in your terminal showing only Microsoft's most popular projects.</p> <p>You have just successfully:</p> <ul> <li>Connected to a live API.</li> <li>Stored results in session variables.</li> <li>Inspected variable structure.</li> <li>Used variables to run subsequent commands.</li> <li>Used a powerful JMESPath query to filter and reshape data on the fly.</li> <li>Rendered the final result as a clean, formatted table.</li> </ul>"},{"location":"tutorials/getting-started/#9-save-your-session","title":"9. Save Your Session","text":"<p>Finally, let's save this entire workspace\u2014including your active <code>gh</code> connection and your <code>msft</code> and <code>repos</code> variables\u2014so you can come back to it later.</p> <pre><code>cx&gt; session save my-first-session\n</code></pre> <p>To exit the shell, type <code>exit</code>. The next time you start <code>cx</code>, you can simply run <code>session load my-first-session</code> to restore your entire workspace instantly.</p>"},{"location":"tutorials/getting-started/#next-steps","title":"Next Steps","text":"<p>You've mastered the core workflow! Now you're ready to explore more powerful features:</p> <ul> <li>How-To: Manage Your Workspace</li> <li>How-To: Build In-Terminal Pipelines</li> <li>Reference: The Interactive Shell Language</li> </ul>"}]}